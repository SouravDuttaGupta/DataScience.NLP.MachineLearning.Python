{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "#### Hate Speech Classification\n",
    "\n",
    "Hate speech is an unfortunately common occurrence on the Internet. Often social media sites like Facebook and Twitter face the problem of identifying and censoring problematic posts while weighing the right to freedom of speech. The importance of detecting and moderating hate speech is evident from the strong connection between hate speech and actual hate crimes. Early identification of users promoting hate speech could enable outreach programs that attempt to prevent an escalation from speech to action.\n",
    "\n",
    "The objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n",
    "\n",
    "Formally, given a training sample of tweets and labels, where label '1' denotes the tweet is racist/sexist and label '0' denotes the tweet is not racist/sexist, your objective is to predict the labels on the test dataset.\n",
    "\n",
    "#### Data Source\n",
    "https://datahack.analyticsvidhya.com/contest/hate-speech-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sourav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "## load dataset\n",
    "\n",
    "#data = pd.read_csv(add)\n",
    "df_train = pd.read_csv(\"train.csv\", encoding='latin-1')\n",
    "df_test = pd.read_csv(\"test_tweets.csv\", encoding='latin-1')\n",
    "#data = pd.read_csv(add, encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...  train\n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...  train\n",
       "2   3    0.0                                bihday your majesty  train\n",
       "3   4    0.0  #model   i love u take with u all the time in ...  train\n",
       "4   5    0.0             factsguide: society now    #motivation  train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine into data:\n",
    "df_train['source']= 'train'\n",
    "df_test['source'] = 'test'\n",
    "\n",
    "data=pd.concat([df_train, df_test],ignore_index=True, sort=False)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...  train\n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...  train\n",
       "2   3    0.0                                bihday your majesty  train\n",
       "3   4    0.0  model   i love u take with u all the time in u...  train\n",
       "4   5    0.0               factsguide society now    motivation  train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df\n",
    "\n",
    "data = clean_text(data, \"tweet\")\n",
    "#train_clean = clean_text(train, \"tweet\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c6b1a3e7c75160b16902579f89d2207bedde5f13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source  \\\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...  train   \n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...  train   \n",
       "2   3    0.0                                bihday your majesty  train   \n",
       "3   4    0.0  model   i love u take with u all the time in u...  train   \n",
       "4   5    0.0               factsguide society now    motivation  train   \n",
       "\n",
       "                                             cleaned  \n",
       "0  father dysfunctional selfish drag kid dysfunct...  \n",
       "1  thank lyft credit cant use cause dont offer wh...  \n",
       "2                                     bihday majesty  \n",
       "3                        model love u take u time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text preprocessing \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    ## lower case \n",
    "    cleaned = text.lower()\n",
    "    \n",
    "    ## remove punctuations\n",
    "    punctuations = string.punctuation\n",
    "    cleaned = \"\".join(character for character in cleaned if character not in punctuations)\n",
    "    \n",
    "    ## remove stopwords \n",
    "    words = cleaned.split()\n",
    "    stopword_lists = stopwords.words(\"english\")\n",
    "    cleaned = [word for word in words if word not in stopword_lists]\n",
    "    \n",
    "    ## normalization - lemmatization\n",
    "    cleaned = [lem.lemmatize(word, \"v\") for word in cleaned]\n",
    "    cleaned = [lem.lemmatize(word, \"n\") for word in cleaned]\n",
    "    \n",
    "    ## join \n",
    "    cleaned = \" \".join(cleaned)\n",
    "    return cleaned\n",
    "\n",
    "data[\"cleaned\"] = data[\"tweet\"].apply(lambda x : clean_text(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature engineering \n",
    "\n",
    "## meta features \n",
    "\n",
    "data[\"word_count\"] = data[\"tweet\"].apply(lambda x : len(x.split()))\n",
    "data[\"word_count_cleand\"] = data[\"cleaned\"].apply(lambda x : len(x.split()))\n",
    "\n",
    "data[\"char_count\"] = data[\"tweet\"].apply(lambda x : len(x))\n",
    "data[\"char_count_without_spaces\"] = data[\"tweet\"].apply(lambda x : len(x.replace(\" \",\"\")))\n",
    "\n",
    "data[\"num_dig\"] = data[\"tweet\"].apply(lambda x :  sum([1 if w.isdigit() else 0 for w in x.split()])                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source  \\\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...  train   \n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...  train   \n",
       "2   3    0.0                                bihday your majesty  train   \n",
       "3   4    0.0  model   i love u take with u all the time in u...  train   \n",
       "4   5    0.0               factsguide society now    motivation  train   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  father dysfunctional selfish drag kid dysfunct...          17   \n",
       "1  thank lyft credit cant use cause dont offer wh...          17   \n",
       "2                                     bihday majesty           3   \n",
       "3                        model love u take u time ur          12   \n",
       "4                      factsguide society motivation           4   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \n",
       "0                  7          95                         75        0  \n",
       "1                 13         106                         85        0  \n",
       "2                  2          21                         17        0  \n",
       "3                  7          50                         34        0  \n",
       "4                  3          37                         30        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dic = {\"noun\" : [\"NNP\", \"NN\", \"NNS\", \"NNPS\"], \"verb\" : [\"VBZ\", \"VB\", \"VBD\",\"VBG\", \"VBN\"]}\n",
    "import nltk\n",
    "def pos_check(txt, family):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(txt))\n",
    "    count = 0\n",
    "    for tag in tags:\n",
    "        tag = tag[1]\n",
    "        if tag in pos_dic[family]:\n",
    "            count += 1 \n",
    "    return count\n",
    "\n",
    "# pos_check(\"They are playing in the ground\", \"verb\")\n",
    "\n",
    "data[\"noun_count\"] = data[\"tweet\"].apply(lambda x : pos_check(x, \"noun\"))\n",
    "data[\"verb_count\"] = data[\"tweet\"].apply(lambda x : pos_check(x, \"verb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source  \\\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...  train   \n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...  train   \n",
       "2   3    0.0                                bihday your majesty  train   \n",
       "3   4    0.0  model   i love u take with u all the time in u...  train   \n",
       "4   5    0.0               factsguide society now    motivation  train   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  father dysfunctional selfish drag kid dysfunct...          17   \n",
       "1  thank lyft credit cant use cause dont offer wh...          17   \n",
       "2                                     bihday majesty           3   \n",
       "3                        model love u take u time ur          12   \n",
       "4                      factsguide society motivation           4   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \\\n",
       "0                  7          95                         75        0   \n",
       "1                 13         106                         85        0   \n",
       "2                  2          21                         17        0   \n",
       "3                  7          50                         34        0   \n",
       "4                  3          37                         30        0   \n",
       "\n",
       "   noun_count  verb_count  \n",
       "0           3           4  \n",
       "1           7           2  \n",
       "2           1           0  \n",
       "3           4           0  \n",
       "4           2           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cvz = CountVectorizer()\n",
    "cvz.fit(data[\"cleaned\"].values)\n",
    "count_vectors = cvz.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49159x48885 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 366047 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tfidf =TfidfVectorizer(max_features=500)\n",
    "word_tfidf.fit(data[\"cleaned\"].values)\n",
    "word_vectors_tfidf = word_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_tfidf =TfidfVectorizer(max_features=500, ngram_range=(1,2))\n",
    "ngram_tfidf.fit(data[\"cleaned\"].values)\n",
    "ngram_tfidf_tfidf = ngram_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tfidf =TfidfVectorizer(max_features=500, analyzer=\"char\")\n",
    "char_tfidf.fit(data[\"cleaned\"].values)\n",
    "char_tfidf_tfidf = char_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.598829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>6.920034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>5.936368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <td>6.740241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adapt</th>\n",
       "      <td>6.696890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affirmation</th>\n",
       "      <td>5.335137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allahsoil</th>\n",
       "      <td>6.847009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>almost</th>\n",
       "      <td>6.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>6.833022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>6.470117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>6.702969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>altwaystoheal</th>\n",
       "      <td>5.665109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>always</th>\n",
       "      <td>5.500217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amaze</th>\n",
       "      <td>5.578277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>6.289407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>6.772398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>4.104353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angry</th>\n",
       "      <td>6.092409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal</th>\n",
       "      <td>6.935301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>5.816384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>6.990651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anymore</th>\n",
       "      <td>6.943023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>6.868362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>6.778955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>6.102392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrive</th>\n",
       "      <td>6.661172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>6.672937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attack</th>\n",
       "      <td>6.153861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>6.289407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>6.132955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wed</th>\n",
       "      <td>6.109103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wednesday</th>\n",
       "      <td>6.890181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>5.085031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekend</th>\n",
       "      <td>5.104568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>5.500217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatever</th>\n",
       "      <td>5.970953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whats</th>\n",
       "      <td>6.632352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>5.894753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whole</th>\n",
       "      <td>6.990651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>6.226886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>5.691368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <td>6.386735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>5.652233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>6.740241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wont</th>\n",
       "      <td>6.460501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>6.261572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>4.878223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>5.289605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>5.867941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>6.413764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>write</th>\n",
       "      <td>6.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong</th>\n",
       "      <td>6.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yay</th>\n",
       "      <td>6.833022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>6.391190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>5.148683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>6.242154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <td>6.904996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>6.413764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>6.465297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youre</th>\n",
       "      <td>5.650103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_tfidf\n",
       "10               6.598829\n",
       "1st              6.920034\n",
       "2016             5.936368\n",
       "act              6.740241\n",
       "adapt            6.696890\n",
       "affirmation      5.335137\n",
       "allahsoil        6.847009\n",
       "almost           6.812403\n",
       "alone            6.833022\n",
       "already          6.470117\n",
       "also             6.702969\n",
       "altwaystoheal    5.665109\n",
       "always           5.500217\n",
       "amaze            5.578277\n",
       "america          6.289407\n",
       "american         6.772398\n",
       "amp              4.104353\n",
       "angry            6.092409\n",
       "animal           6.935301\n",
       "another          5.816384\n",
       "anxiety          6.990651\n",
       "anymore          6.943023\n",
       "anyone           6.868362\n",
       "anything         6.778955\n",
       "around           6.102392\n",
       "arrive           6.661172\n",
       "ask              6.672937\n",
       "attack           6.153861\n",
       "away             6.289407\n",
       "awesome          6.132955\n",
       "...                   ...\n",
       "wed              6.109103\n",
       "wednesday        6.890181\n",
       "week             5.085031\n",
       "weekend          5.104568\n",
       "well             5.500217\n",
       "whatever         5.970953\n",
       "whats            6.632352\n",
       "white            5.894753\n",
       "whole            6.990651\n",
       "win              6.226886\n",
       "wish             5.691368\n",
       "without          6.386735\n",
       "woman            5.652233\n",
       "wonderful        6.740241\n",
       "wont             6.460501\n",
       "word             6.261572\n",
       "work             4.878223\n",
       "world            5.289605\n",
       "would            5.867941\n",
       "wow              6.413764\n",
       "write            6.812403\n",
       "wrong            6.812403\n",
       "yay              6.833022\n",
       "yeah             6.391190\n",
       "year             5.148683\n",
       "yes              6.242154\n",
       "yesterday        6.904996\n",
       "yet              6.413764\n",
       "young            6.465297\n",
       "youre            5.650103\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = dict(zip(word_tfidf.get_feature_names(), word_tfidf.idf_))\n",
    "tfidf_idf = pd.DataFrame(columns=[\"word_tfidf\"]).from_dict(tfidf, orient=\"index\")\n",
    "tfidf_idf.columns=[\"word_tfidf\"]\n",
    "tfidf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0e20242470db5f225823acfbe524f7adb8c0a9f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>char_nospace_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22 huge fan fare and big talking before they l...</td>\n",
       "      <td>train</td>\n",
       "      <td>22 huge fan fare big talk leave chaos pay disp...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>camping tomorrow        danny</td>\n",
       "      <td>train</td>\n",
       "      <td>camp tomorrow danny</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the next school year is the year for exams can...</td>\n",
       "      <td>train</td>\n",
       "      <td>next school year year exam cant think school e...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we won love the land allin cavs champions clev...</td>\n",
       "      <td>train</td>\n",
       "      <td>love land allin cavs champion cleveland clevel...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welcome here   im   its so gr8</td>\n",
       "      <td>train</td>\n",
       "      <td>welcome im gr8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ireland consumer price index mom climbed fro...</td>\n",
       "      <td>train</td>\n",
       "      <td>ireland consumer price index mom climb previou...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we are so selfish orlando standwithorlando pul...</td>\n",
       "      <td>train</td>\n",
       "      <td>selfish orlando standwithorlando pulseshooting...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i get to see my daddy today   80days gettingfed</td>\n",
       "      <td>train</td>\n",
       "      <td>get see daddy today 80days gettingfed</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cnn calls michigan middle school build the wa...</td>\n",
       "      <td>train</td>\n",
       "      <td>cnn call michigan middle school build wall cha...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no comment  in australia   opkillingbay seashe...</td>\n",
       "      <td>train</td>\n",
       "      <td>comment australia opkillingbay seashepherd hel...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ouchjunior is angrygot7 junior yugyoem   omg</td>\n",
       "      <td>train</td>\n",
       "      <td>ouchjunior angrygot7 junior yugyoem omg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am thankful for having a paner thankful posi...</td>\n",
       "      <td>train</td>\n",
       "      <td>thankful paner thankful positive</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>retweet if you agree</td>\n",
       "      <td>train</td>\n",
       "      <td>retweet agree</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>its friday  smiles all around via ig user  coo...</td>\n",
       "      <td>train</td>\n",
       "      <td>friday smile around via ig user cooky make people</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>as we all know essential oils are not made of ...</td>\n",
       "      <td>train</td>\n",
       "      <td>know essential oil make chemical</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>euro2016 people blaming ha for conceded goal w...</td>\n",
       "      <td>train</td>\n",
       "      <td>euro2016 people blame ha concede goal fat roon...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>82</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sad little dude   badday coneofshame cats piss...</td>\n",
       "      <td>train</td>\n",
       "      <td>sad little dude badday coneofshame cat piss fu...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>product of the day happy man wine tool  whos  ...</td>\n",
       "      <td>train</td>\n",
       "      <td>product day happy man wine tool who weekend ti...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lumpy says i am a  prove it lumpy</td>\n",
       "      <td>train</td>\n",
       "      <td>lumpy say prove lumpy</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tgif   ff to my gamedev indiedev indiegamede...</td>\n",
       "      <td>train</td>\n",
       "      <td>tgif ff gamedev indiedev indiegamedev squad</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>beautiful sign by vendor 80 for 4500 upsideoff...</td>\n",
       "      <td>train</td>\n",
       "      <td>beautiful sign vendor 80 4500 upsideofflorida ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>all smiles when media is     pressconference...</td>\n",
       "      <td>train</td>\n",
       "      <td>smile medium pressconference antalya turkey su...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we had a great panel on the mediatization of t...</td>\n",
       "      <td>train</td>\n",
       "      <td>great panel mediatization public service ica16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>happy fathers day</td>\n",
       "      <td>train</td>\n",
       "      <td>happy father day</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50 people went to nightclub to have a good nig...</td>\n",
       "      <td>train</td>\n",
       "      <td>50 people go nightclub good night 1 man action...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>89</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49129</th>\n",
       "      <td>49130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people do anything for fucking attention nowad...</td>\n",
       "      <td>test</td>\n",
       "      <td>people anything fuck attention nowadays</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49130</th>\n",
       "      <td>49131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>creative bubble got burst  looking forward to ...</td>\n",
       "      <td>test</td>\n",
       "      <td>creative bubble get burst look forward day nev...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49131</th>\n",
       "      <td>49132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tomorrow is gonna be a big day we are going to...</td>\n",
       "      <td>test</td>\n",
       "      <td>tomorrow gonna big day go deliver first box bo...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49132</th>\n",
       "      <td>49133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am thankful for baby giggles thankful positi...</td>\n",
       "      <td>test</td>\n",
       "      <td>thankful baby giggle thankful positive</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49133</th>\n",
       "      <td>49134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>test</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49134</th>\n",
       "      <td>49135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in life u will grow to learn some pple will wo...</td>\n",
       "      <td>test</td>\n",
       "      <td>life u grow learn pple work fuck u coz ur life...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49135</th>\n",
       "      <td>49136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i was the stormyou were the rain together we d...</td>\n",
       "      <td>test</td>\n",
       "      <td>stormyou rain together destroy town become nam...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49136</th>\n",
       "      <td>49137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lovelgq   broken ep via   rnb love heabroken h...</td>\n",
       "      <td>test</td>\n",
       "      <td>lovelgq break ep via rnb love heabroken hea dr...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49137</th>\n",
       "      <td>49138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spread love not hate prayingfororlando   lovea...</td>\n",
       "      <td>test</td>\n",
       "      <td>spread love hate prayingfororlando loveanother...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49138</th>\n",
       "      <td>49139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>are the most racist pay ever</td>\n",
       "      <td>test</td>\n",
       "      <td>racist pay ever</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49139</th>\n",
       "      <td>49140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am thankful for children thankful positive</td>\n",
       "      <td>test</td>\n",
       "      <td>thankful child thankful positive</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49140</th>\n",
       "      <td>49141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liverpool  walk liverpool starbucks avidaeboa ...</td>\n",
       "      <td>test</td>\n",
       "      <td>liverpool walk liverpool starbucks avidaeboa p...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49141</th>\n",
       "      <td>49142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bakersfield   rooster simulation i want to cli...</td>\n",
       "      <td>test</td>\n",
       "      <td>bakersfield rooster simulation want climb vast...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49142</th>\n",
       "      <td>49143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>por do sol instagood beautiful   instadaily in...</td>\n",
       "      <td>test</td>\n",
       "      <td>por sol instagood beautiful instadaily instali...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49143</th>\n",
       "      <td>49144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hell yeah what a great surprise for your pres...</td>\n",
       "      <td>test</td>\n",
       "      <td>hell yeah great surprise present enjoy picture...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49144</th>\n",
       "      <td>49145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when ur the joke ur defensive towards everything</td>\n",
       "      <td>test</td>\n",
       "      <td>ur joke ur defensive towards everything</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49145</th>\n",
       "      <td>49146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enjoying the evening sun in my bedroom    cozy...</td>\n",
       "      <td>test</td>\n",
       "      <td>enjoy even sun bedroom cozy even homesweethome...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49146</th>\n",
       "      <td>49147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tonight on  from 9pm gmt  you can here a speci...</td>\n",
       "      <td>test</td>\n",
       "      <td>tonight 9pm gmt special early play new song up...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49147</th>\n",
       "      <td>49148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>today is a good day for excercise imready sofu...</td>\n",
       "      <td>test</td>\n",
       "      <td>today good day excercise imready sofuckenready...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49148</th>\n",
       "      <td>49149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good night with a tea and music  billy music t...</td>\n",
       "      <td>test</td>\n",
       "      <td>good night tea music billy music tea mug tokio...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49149</th>\n",
       "      <td>49150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>loving life  createyourfuture   lifestyle holi...</td>\n",
       "      <td>test</td>\n",
       "      <td>love life createyourfuture lifestyle holiday l...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49150</th>\n",
       "      <td>49151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black professor demonizes proposes nazi style ...</td>\n",
       "      <td>test</td>\n",
       "      <td>black professor demonize propose nazi style co...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49151</th>\n",
       "      <td>49152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>learn how to think positive  positive   instag...</td>\n",
       "      <td>test</td>\n",
       "      <td>learn think positive positive instagram instagood</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49152</th>\n",
       "      <td>49153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we love the pretty happy and fresh you teenili...</td>\n",
       "      <td>test</td>\n",
       "      <td>love pretty happy fresh teenilicious fixdermat...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49153</th>\n",
       "      <td>49154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2damntuffruffmufftechnocityng005web1997ukhxint...</td>\n",
       "      <td>test</td>\n",
       "      <td>2damntuffruffmufftechnocityng005web1997ukhxint...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory leftright polarisation trump u...</td>\n",
       "      <td>test</td>\n",
       "      <td>think factory leftright polarisation trump use...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid  hairflip neverready fo...</td>\n",
       "      <td>test</td>\n",
       "      <td>feel like mermaid hairflip neverready formal w...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hillary campaigned today in ohioomg amp used w...</td>\n",
       "      <td>test</td>\n",
       "      <td>hillary campaign today ohioomg amp use word li...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "      <td>test</td>\n",
       "      <td>happy work conference right mindset lead cultu...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song so glad free download  shoegaze newm...</td>\n",
       "      <td>test</td>\n",
       "      <td>song glad free download shoegaze newmusic newsong</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet source  \\\n",
       "0          1    0.0    when a father is dysfunctional and is so sel...  train   \n",
       "1          2    0.0    thanks for lyft credit i cant use cause they...  train   \n",
       "2          3    0.0                                bihday your majesty  train   \n",
       "3          4    0.0  model   i love u take with u all the time in u...  train   \n",
       "4          5    0.0               factsguide society now    motivation  train   \n",
       "5          6    0.0  22 huge fan fare and big talking before they l...  train   \n",
       "6          7    0.0                      camping tomorrow        danny  train   \n",
       "7          8    0.0  the next school year is the year for exams can...  train   \n",
       "8          9    0.0  we won love the land allin cavs champions clev...  train   \n",
       "9         10    0.0                   welcome here   im   its so gr8    train   \n",
       "10        11    0.0    ireland consumer price index mom climbed fro...  train   \n",
       "11        12    0.0  we are so selfish orlando standwithorlando pul...  train   \n",
       "12        13    0.0    i get to see my daddy today   80days gettingfed  train   \n",
       "13        14    1.0   cnn calls michigan middle school build the wa...  train   \n",
       "14        15    1.0  no comment  in australia   opkillingbay seashe...  train   \n",
       "15        16    0.0      ouchjunior is angrygot7 junior yugyoem   omg   train   \n",
       "16        17    0.0  i am thankful for having a paner thankful posi...  train   \n",
       "17        18    1.0                              retweet if you agree   train   \n",
       "18        19    0.0  its friday  smiles all around via ig user  coo...  train   \n",
       "19        20    0.0  as we all know essential oils are not made of ...  train   \n",
       "20        21    0.0  euro2016 people blaming ha for conceded goal w...  train   \n",
       "21        22    0.0  sad little dude   badday coneofshame cats piss...  train   \n",
       "22        23    0.0  product of the day happy man wine tool  whos  ...  train   \n",
       "23        24    1.0                  lumpy says i am a  prove it lumpy  train   \n",
       "24        25    0.0    tgif   ff to my gamedev indiedev indiegamede...  train   \n",
       "25        26    0.0  beautiful sign by vendor 80 for 4500 upsideoff...  train   \n",
       "26        27    0.0    all smiles when media is     pressconference...  train   \n",
       "27        28    0.0  we had a great panel on the mediatization of t...  train   \n",
       "28        29    0.0                              happy fathers day      train   \n",
       "29        30    0.0  50 people went to nightclub to have a good nig...  train   \n",
       "...      ...    ...                                                ...    ...   \n",
       "49129  49130    NaN  people do anything for fucking attention nowad...   test   \n",
       "49130  49131    NaN  creative bubble got burst  looking forward to ...   test   \n",
       "49131  49132    NaN  tomorrow is gonna be a big day we are going to...   test   \n",
       "49132  49133    NaN  i am thankful for baby giggles thankful positi...   test   \n",
       "49133  49134    NaN  model   i love u take with u all the time in u...   test   \n",
       "49134  49135    NaN  in life u will grow to learn some pple will wo...   test   \n",
       "49135  49136    NaN  i was the stormyou were the rain together we d...   test   \n",
       "49136  49137    NaN  lovelgq   broken ep via   rnb love heabroken h...   test   \n",
       "49137  49138    NaN  spread love not hate prayingfororlando   lovea...   test   \n",
       "49138  49139    NaN                      are the most racist pay ever    test   \n",
       "49139  49140    NaN  i am thankful for children thankful positive        test   \n",
       "49140  49141    NaN  liverpool  walk liverpool starbucks avidaeboa ...   test   \n",
       "49141  49142    NaN  bakersfield   rooster simulation i want to cli...   test   \n",
       "49142  49143    NaN  por do sol instagood beautiful   instadaily in...   test   \n",
       "49143  49144    NaN   hell yeah what a great surprise for your pres...   test   \n",
       "49144  49145    NaN  when ur the joke ur defensive towards everything    test   \n",
       "49145  49146    NaN  enjoying the evening sun in my bedroom    cozy...   test   \n",
       "49146  49147    NaN  tonight on  from 9pm gmt  you can here a speci...   test   \n",
       "49147  49148    NaN  today is a good day for excercise imready sofu...   test   \n",
       "49148  49149    NaN  good night with a tea and music  billy music t...   test   \n",
       "49149  49150    NaN  loving life  createyourfuture   lifestyle holi...   test   \n",
       "49150  49151    NaN  black professor demonizes proposes nazi style ...   test   \n",
       "49151  49152    NaN  learn how to think positive  positive   instag...   test   \n",
       "49152  49153    NaN  we love the pretty happy and fresh you teenili...   test   \n",
       "49153  49154    NaN  2damntuffruffmufftechnocityng005web1997ukhxint...   test   \n",
       "49154  49155    NaN  thought factory leftright polarisation trump u...   test   \n",
       "49155  49156    NaN  feeling like a mermaid  hairflip neverready fo...   test   \n",
       "49156  49157    NaN  hillary campaigned today in ohioomg amp used w...   test   \n",
       "49157  49158    NaN  happy at work conference right mindset leads t...   test   \n",
       "49158  49159    NaN  my   song so glad free download  shoegaze newm...   test   \n",
       "\n",
       "                                                 cleaned  word_count  \\\n",
       "0      father dysfunctional selfish drag kid dysfunct...           7   \n",
       "1      thank lyft credit cant use cause dont offer wh...          13   \n",
       "2                                         bihday majesty           2   \n",
       "3                            model love u take u time ur           7   \n",
       "4                          factsguide society motivation           3   \n",
       "5      22 huge fan fare big talk leave chaos pay disp...          12   \n",
       "6                                    camp tomorrow danny           3   \n",
       "7      next school year year exam cant think school e...          14   \n",
       "8      love land allin cavs champion cleveland clevel...           7   \n",
       "9                                         welcome im gr8           3   \n",
       "10     ireland consumer price index mom climb previou...          14   \n",
       "11     selfish orlando standwithorlando pulseshooting...          10   \n",
       "12                 get see daddy today 80days gettingfed           6   \n",
       "13     cnn call michigan middle school build wall cha...           9   \n",
       "14     comment australia opkillingbay seashepherd hel...           7   \n",
       "15               ouchjunior angrygot7 junior yugyoem omg           5   \n",
       "16                      thankful paner thankful positive           4   \n",
       "17                                         retweet agree           2   \n",
       "18     friday smile around via ig user cooky make people           9   \n",
       "19                      know essential oil make chemical           5   \n",
       "20     euro2016 people blame ha concede goal fat roon...          15   \n",
       "21     sad little dude badday coneofshame cat piss fu...           9   \n",
       "22     product day happy man wine tool who weekend ti...          12   \n",
       "23                                 lumpy say prove lumpy           4   \n",
       "24           tgif ff gamedev indiedev indiegamedev squad           6   \n",
       "25     beautiful sign vendor 80 4500 upsideofflorida ...           8   \n",
       "26     smile medium pressconference antalya turkey su...           8   \n",
       "27        great panel mediatization public service ica16           6   \n",
       "28                                      happy father day           3   \n",
       "29     50 people go nightclub good night 1 man action...          15   \n",
       "...                                                  ...         ...   \n",
       "49129            people anything fuck attention nowadays           5   \n",
       "49130  creative bubble get burst look forward day nev...          11   \n",
       "49131  tomorrow gonna big day go deliver first box bo...          12   \n",
       "49132             thankful baby giggle thankful positive           5   \n",
       "49133                        model love u take u time ur           7   \n",
       "49134  life u grow learn pple work fuck u coz ur life...          17   \n",
       "49135  stormyou rain together destroy town become nam...           9   \n",
       "49136  lovelgq break ep via rnb love heabroken hea dr...          14   \n",
       "49137  spread love hate prayingfororlando loveanother...           7   \n",
       "49138                                    racist pay ever           3   \n",
       "49139                   thankful child thankful positive           4   \n",
       "49140  liverpool walk liverpool starbucks avidaeboa p...           8   \n",
       "49141  bakersfield rooster simulation want climb vast...          11   \n",
       "49142  por sol instagood beautiful instadaily instali...          10   \n",
       "49143  hell yeah great surprise present enjoy picture...           8   \n",
       "49144            ur joke ur defensive towards everything           6   \n",
       "49145  enjoy even sun bedroom cozy even homesweethome...           8   \n",
       "49146  tonight 9pm gmt special early play new song up...          10   \n",
       "49147  today good day excercise imready sofuckenready...           9   \n",
       "49148  good night tea music billy music tea mug tokio...          10   \n",
       "49149  love life createyourfuture lifestyle holiday l...          10   \n",
       "49150  black professor demonize propose nazi style co...          13   \n",
       "49151  learn think positive positive instagram instagood           6   \n",
       "49152  love pretty happy fresh teenilicious fixdermat...           9   \n",
       "49153  2damntuffruffmufftechnocityng005web1997ukhxint...           5   \n",
       "49154  think factory leftright polarisation trump use...          11   \n",
       "49155  feel like mermaid hairflip neverready formal w...          10   \n",
       "49156  hillary campaign today ohioomg amp use word li...          14   \n",
       "49157  happy work conference right mindset lead cultu...          10   \n",
       "49158  song glad free download shoegaze newmusic newsong           7   \n",
       "\n",
       "       word_count_cleand  char_count  char_count_without_spaces  num_dig  \\\n",
       "0                      7          53                         75        0   \n",
       "1                     13          85                         85        0   \n",
       "2                      2          14                         17        0   \n",
       "3                      7          27                         34        0   \n",
       "4                      3          29                         30        0   \n",
       "5                     12          68                         90        1   \n",
       "6                      3          19                         20        0   \n",
       "7                     14          95                        104        0   \n",
       "8                      7          58                         61        0   \n",
       "9                      3          14                         21        0   \n",
       "10                    14          80                         77        2   \n",
       "11                    10         108                        107        0   \n",
       "12                     6          37                         37        0   \n",
       "13                     9          53                         49        0   \n",
       "14                     7          84                         82        0   \n",
       "15                     5          39                         37        0   \n",
       "16                     4          32                         42        0   \n",
       "17                     2          13                         17        0   \n",
       "18                     9          49                         50        0   \n",
       "19                     5          32                         45        0   \n",
       "20                    15          82                        101        0   \n",
       "21                     9          55                         51        0   \n",
       "22                    12          63                         70        0   \n",
       "23                     4          21                         25        0   \n",
       "24                     6          43                         42        0   \n",
       "25                     8          62                         60        2   \n",
       "26                     8          65                         69        0   \n",
       "27                     6          46                         57        0   \n",
       "28                     3          16                         15        0   \n",
       "29                    15          89                        109        2   \n",
       "...                  ...         ...                        ...      ...   \n",
       "49129                  5          39                         43        0   \n",
       "49130                 11          66                         78        0   \n",
       "49131                 12          67                         78        0   \n",
       "49132                  5          38                         41        0   \n",
       "49133                  7          27                         34        0   \n",
       "49134                 17          75                         88        0   \n",
       "49135                  9          61                         79        0   \n",
       "49136                 14          90                         78        0   \n",
       "49137                  7          60                         57        0   \n",
       "49138                  3          15                         23        0   \n",
       "49139                  4          32                         38        0   \n",
       "49140                  8          72                         65        0   \n",
       "49141                 11          81                         87        0   \n",
       "49142                 10          82                         77        0   \n",
       "49143                  8          53                         66        0   \n",
       "49144                  6          39                         41        0   \n",
       "49145                  8          55                         64        0   \n",
       "49146                 10          58                         76        0   \n",
       "49147                  9          71                         69        0   \n",
       "49148                 10          65                         64        0   \n",
       "49149                 10          72                         65        0   \n",
       "49150                 13          93                         89        0   \n",
       "49151                  6          49                         49        0   \n",
       "49152                  9          74                         77        0   \n",
       "49153                  5          69                         65        0   \n",
       "49154                 11          93                         85        0   \n",
       "49155                 10          67                         68        0   \n",
       "49156                 14         109                        109        0   \n",
       "49157                 10          87                         84        0   \n",
       "49158                  7          49                         47        0   \n",
       "\n",
       "       noun_count  verb_count  digit_count  upper_count  char_nospace_count  \n",
       "0               3           4            0            0                  47  \n",
       "1               7           2            0            0                  73  \n",
       "2               1           0            0            0                  13  \n",
       "3               4           0            0            0                  21  \n",
       "4               2           0            0            0                  27  \n",
       "5               4           2            1            0                  57  \n",
       "6               2           1            0            0                  17  \n",
       "7               8           1            0            0                  82  \n",
       "8               5           2            0            0                  52  \n",
       "9               1           1            0            0                  12  \n",
       "10              5           5            2            0                  67  \n",
       "11              4           4            0            0                  99  \n",
       "12              4           1            0            0                  32  \n",
       "13              5           1            0            0                  45  \n",
       "14              4           0            0            0                  78  \n",
       "15              3           1            0            0                  35  \n",
       "16              3           1            0            0                  29  \n",
       "17              1           0            0            0                  12  \n",
       "18              5           0            0            0                  41  \n",
       "19              2           1            0            0                  28  \n",
       "20              6           5            0            0                  68  \n",
       "21              5           1            0            0                  47  \n",
       "22              8           3            0            0                  52  \n",
       "23              3           2            0            0                  18  \n",
       "24              6           0            0            0                  38  \n",
       "25              3           0            2            0                  55  \n",
       "26              6           1            0            0                  58  \n",
       "27              4           1            0            0                  41  \n",
       "28              2           0            0            0                  14  \n",
       "29              6           5            2            0                  75  \n",
       "...           ...         ...          ...          ...                 ...  \n",
       "49129           4           1            0            0                  35  \n",
       "49130           3           4            0            0                  56  \n",
       "49131           5           5            0            0                  56  \n",
       "49132           3           0            0            0                  34  \n",
       "49133           4           0            0            0                  21  \n",
       "49134           7           6            0            0                  59  \n",
       "49135           5           5            0            0                  53  \n",
       "49136           8           1            0            0                  77  \n",
       "49137           3           1            0            0                  54  \n",
       "49138           1           0            0            0                  13  \n",
       "49139           3           0            0            0                  29  \n",
       "49140           5           0            0            0                  65  \n",
       "49141           8           2            0            0                  71  \n",
       "49142           5           2            0            0                  73  \n",
       "49143           5           1            0            0                  46  \n",
       "49144           3           1            0            0                  34  \n",
       "49145           5           2            0            0                  48  \n",
       "49146           5           0            0            0                  49  \n",
       "49147           6           1            0            0                  63  \n",
       "49148           8           0            0            0                  56  \n",
       "49149           5           1            0            0                  63  \n",
       "49150           6           2            0            0                  81  \n",
       "49151           2           2            0            0                  44  \n",
       "49152           2           0            0            0                  66  \n",
       "49153           3           0            0            0                  65  \n",
       "49154           7           0            0            0                  83  \n",
       "49155           3           3            0            0                  58  \n",
       "49156           9           4            0            0                  96  \n",
       "49157           5           2            0            0                  78  \n",
       "49158           4           0            0            0                  43  \n",
       "\n",
       "[49159 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## feature engineering \n",
    "\n",
    "## meta features\n",
    "data[\"cleaned\"] = data[\"cleaned\"].fillna(\"\")\n",
    "\n",
    "data[\"digit_count\"] = data[\"tweet\"].apply(lambda x : sum([1 if w.isdigit() else 0 for w in x.split()]))\n",
    "data[\"upper_count\"] = data[\"tweet\"].apply(lambda x : sum([1 if w.isupper() else 0 for w in x.split()]))\n",
    "data[\"word_count\"] = data[\"cleaned\"].apply(lambda x: len(x.split()))\n",
    "data[\"char_count\"] = data[\"cleaned\"].apply(lambda x: len(x))\n",
    "data[\"char_nospace_count\"] = data[\"cleaned\"].apply(lambda x: len(x.replace(\" \",\"\")))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1a7989cb1ca5978a5f87140e417e27c1ad0dbfa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>char_nospace_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>train</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>train</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>train</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>train</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>train</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet source  \\\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...  train   \n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...  train   \n",
       "2   3    0.0                                bihday your majesty  train   \n",
       "3   4    0.0  model   i love u take with u all the time in u...  train   \n",
       "4   5    0.0               factsguide society now    motivation  train   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  father dysfunctional selfish drag kid dysfunct...           7   \n",
       "1  thank lyft credit cant use cause dont offer wh...          13   \n",
       "2                                     bihday majesty           2   \n",
       "3                        model love u take u time ur           7   \n",
       "4                      factsguide society motivation           3   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \\\n",
       "0                  7          53                         75        0   \n",
       "1                 13          85                         85        0   \n",
       "2                  2          14                         17        0   \n",
       "3                  7          27                         34        0   \n",
       "4                  3          29                         30        0   \n",
       "\n",
       "   noun_count  verb_count  digit_count  upper_count  char_nospace_count  \n",
       "0           3           1            0            0                  47  \n",
       "1          10           3            0            0                  73  \n",
       "2           2           0            0            0                  13  \n",
       "3           3           1            0            0                  21  \n",
       "4           2           0            0            0                  27  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nlp based features \n",
    "\n",
    "pos_dic = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "def pos_check(x, flag):\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(x))\n",
    "    count = 0\n",
    "    for tag in tags:\n",
    "        tag = tag[1]\n",
    "        if tag in pos_dic[flag]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "data['noun_count'] = data['cleaned'].apply(lambda x: pos_check(x, 'noun'))\n",
    "data['verb_count'] = data['cleaned'].apply(lambda x: pos_check(x, 'verb'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "968c73b132860c4bb841f148bc766a285e869f06"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cvz = CountVectorizer(analyzer='word') \n",
    "cvz.fit(data[\"cleaned\"].values)\n",
    "count_vectors = cvz.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49159x48885 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 366047 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "96cb4e05f4d2122dc37cc9c70d79b22ee11d889e"
   },
   "outputs": [],
   "source": [
    "word_tfidf = TfidfVectorizer(analyzer='word') \n",
    "word_tfidf.fit(data[\"cleaned\"].values)\n",
    "word_vectors_tfidf = word_tfidf.transform(data[\"cleaned\"].values)\n",
    "\n",
    "ngram_tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,3)) \n",
    "ngram_tfidf.fit(data[\"cleaned\"].values)\n",
    "ngarm_vectors_tfidf = ngram_tfidf.transform(data[\"cleaned\"].values)\n",
    "\n",
    "char_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(1,3)) \n",
    "char_tfidf.fit(data[\"cleaned\"].values)\n",
    "char_vectors_tfidf = char_tfidf.transform(data[\"cleaned\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "d08dafd8012069195f4b3d3f2f92150c9e2f39a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>11.109688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morelebronexcuses</th>\n",
       "      <td>11.109688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morellisices</th>\n",
       "      <td>11.109688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morelovelesshate</th>\n",
       "      <td>11.109688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moremulaaaa</th>\n",
       "      <td>11.109688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title_word_tfidf\n",
       "000                       11.109688\n",
       "morelebronexcuses         11.109688\n",
       "morellisices              11.109688\n",
       "morelovelesshate          11.109688\n",
       "moremulaaaa               11.109688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = dict(zip(word_tfidf.get_feature_names(), word_tfidf.idf_))\n",
    "tfidf = pd.DataFrame(columns=['title_word_tfidf']).from_dict(dict(tfidf), orient='index')\n",
    "tfidf.columns = ['title_word_tfidf']\n",
    "tfidf.sort_values(by=['title_word_tfidf'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "c7645016cb25bb35baf2c134a40e88cf1b6bd68f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_word_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>4.104353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>3.984808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>3.942265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>3.555092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>3.433447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_word_tfidf\n",
       "amp            4.104353\n",
       "happy          3.984808\n",
       "get            3.942265\n",
       "day            3.555092\n",
       "love           3.433447"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.sort_values(by=['title_word_tfidf'], ascending=False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet', 'source', 'cleaned', 'word_count',\n",
       "       'word_count_cleand', 'char_count', 'char_count_without_spaces',\n",
       "       'num_dig', 'noun_count', 'verb_count', 'digit_count', 'upper_count',\n",
       "       'char_nospace_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train & test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['source']=='train']\n",
    "test = data.loc[data['source']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sourav\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train.drop('source',axis=1,inplace=True)\n",
    "test.drop(['source','label'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_modified.csv',index=False)\n",
    "test.to_csv('test_modified.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_cleand</th>\n",
       "      <th>char_count</th>\n",
       "      <th>char_count_without_spaces</th>\n",
       "      <th>num_dig</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>digit_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>char_nospace_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "      <td>father dysfunctional selfish drag kid dysfunct...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit i cant use cause they...</td>\n",
       "      <td>thank lyft credit cant use cause dont offer wh...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model   i love u take with u all the time in u...</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now    motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...   \n",
       "1   2    0.0    thanks for lyft credit i cant use cause they...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  model   i love u take with u all the time in u...   \n",
       "4   5    0.0               factsguide society now    motivation   \n",
       "\n",
       "                                             cleaned  word_count  \\\n",
       "0  father dysfunctional selfish drag kid dysfunct...           7   \n",
       "1  thank lyft credit cant use cause dont offer wh...          13   \n",
       "2                                     bihday majesty           2   \n",
       "3                        model love u take u time ur           7   \n",
       "4                      factsguide society motivation           3   \n",
       "\n",
       "   word_count_cleand  char_count  char_count_without_spaces  num_dig  \\\n",
       "0                  7          53                         75        0   \n",
       "1                 13          85                         85        0   \n",
       "2                  2          14                         17        0   \n",
       "3                  7          27                         34        0   \n",
       "4                  3          29                         30        0   \n",
       "\n",
       "   noun_count  verb_count  digit_count  upper_count  char_nospace_count  \n",
       "0           3           1            0            0                  47  \n",
       "1          10           3            0            0                  73  \n",
       "2           2           0            0            0                  13  \n",
       "3           3           1            0            0                  21  \n",
       "4           2           0            0            0                  27  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Fit Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified = pd.read_csv('train_modified.csv')\n",
    "test_modified = pd.read_csv('test_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "predictors = ['digit_count', 'upper_count', 'word_count', 'char_count', 'char_nospace_count', 'noun_count', 'verb_count']\n",
    "\n",
    "Xtrain = train_modified[predictors]\n",
    "Ytrain = train_modified['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "meta_features = ['digit_count', 'upper_count', 'word_count', 'char_count', 'char_nospace_count', 'noun_count', 'verb_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_set1 = train_mod[meta_features]\n",
    "train = hstack([word_vectors_tfidf, csr_matrix(feature_set1)], 'csr')\n",
    "target = train_mod['label'].values\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature_set1 = test_mod[meta_features]\n",
    "test_meta = hstack([word_vectors_tfidf, csr_matrix(feature_set1)], 'csr')\n",
    "test_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target='label'\n",
    "IDcol = 'id'\n",
    "\n",
    "Ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "a99be3c2db8d7c152ca74b1eab1ed26bb9e19432"
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "2fdae7450be9bf493a50179e885b778b5a6d2217"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-9656b3e28835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape ()"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "target = LabelEncoder().fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "#predictors = [x for x in train.columns if x not in [target, IDcol]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "a61652334908d4e1a01ba71cead11bdd8b702330"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, valx, trainy, valy = train_test_split(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model: NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "4605e907c822edf5cb6f8feddac1d12b15da079d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train): 0.929045\n",
      "F1 Score (Train): 0.963218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "## NaiveBayes\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(trainx, trainy)\n",
    "preds = model.predict(valx)\n",
    "accur = accuracy_score(preds, valy)\n",
    "f1 = f1_score(valy, preds, average='weighted', labels=np.unique(preds))\n",
    "\n",
    "print('Accuracy Score (Train): %f' % accur)\n",
    "print('F1 Score (Train): %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "6a55f11a6a32cb703f56ba4e6829ca0cb84918df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train): 0.929045\n",
      "F1 Score (Train): 0.963218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sourav\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(trainx, trainy)\n",
    "preds = model.predict(valx)\n",
    "accur = accuracy_score(preds, valy)\n",
    "f1 = f1_score(valy, preds, average='weighted', labels=np.unique(preds))\n",
    "\n",
    "print('Accuracy Score (Train): %f' % accur)\n",
    "print('F1 Score (Train): %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "3bfb49d56112d808dfb88886125fb35a689a4cd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sourav\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train): 0.929796\n",
      "F1 Score (Train): 0.896707\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(trainx, trainy)\n",
    "preds = model.predict(valx)\n",
    "accur = accuracy_score(preds, valy)\n",
    "f1 = f1_score(valy, preds, average='weighted', labels=np.unique(preds))\n",
    "\n",
    "print('Accuracy Score (Train): %f' % accur)\n",
    "print('F1 Score (Train): %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "b318a4113b1d267340f9a6a0b919906111feafcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train): 0.929796\n",
      "F1 Score (Train): 0.896707\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBClassifier()\n",
    "model.fit(trainx, trainy)\n",
    "preds = model.predict(valx)\n",
    "accur = accuracy_score(preds, valy)\n",
    "f1 = f1_score(valy, preds, average='weighted', labels=np.unique(preds))\n",
    "\n",
    "print('Accuracy Score (Train): %f' % accur)\n",
    "print('F1 Score (Train): %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "8733e71597d6acb5580e406b33c80feda0f56ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Train): 0.925541\n",
      "F1 Score (Train): 0.908625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sourav\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.ExtraTreesClassifier()\n",
    "model.fit(trainx, trainy)\n",
    "preds = model.predict(valx)\n",
    "accur = accuracy_score(preds, valy)\n",
    "f1 = f1_score(valy, preds, average='weighted', labels=np.unique(preds))\n",
    "\n",
    "print('Accuracy Score (Train): %f' % accur)\n",
    "print('F1 Score (Train): %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
